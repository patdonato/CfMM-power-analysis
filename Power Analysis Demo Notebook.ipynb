{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘dataiku’ was built under R version 4.1.3”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"SEARCHING FOR \"\n",
      "[1] \"pwr_analysis.R\"\n",
      "[1] \"IN\"\n",
      "[1] \"/data/dataiku/dss_data/jupyter-run/dku-workdirs/TEST_26/Power_Analysis_Demo_Notebooka4c6978a-dssuser_donatpat/project-r-src/TEST_26/R\"\n",
      "[1] \"Loading source file /data/dataiku/dss_data/jupyter-run/dku-workdirs/TEST_26/Power_Analysis_Demo_Notebooka4c6978a-dssuser_donatpat/project-r-src/TEST_26/R/pwr_analysis.R\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.6      \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.8      \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.10\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.1      \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.1 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.2      \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.2 \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(dataiku)\n",
    "dkuSourceLibR(\"pwr_analysis.R\")\n",
    "\n",
    "# Change to the ff if running on your local machine:\n",
    "# source(\"pwr_analysis.R\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for Apriori Power Analysis\n",
    "\n",
    "**Objective**\n",
    "- Apriori power analysis is conducted before data collection to determine the required sample size needed to achieve a desired level of power, typically 80% or 90%. It ensures that the study is adequately powered to detect a meaningful effect.\n",
    "- Unlike post hoc power analysis, which evaluates power after a study is conducted, apriori analysis is prospective and used for study planning.\n",
    "\n",
    "**When to use it?**\n",
    "- When designing a study to determine the necessary sample size.\n",
    "- When ensuring that the study has a high probability of detecting a real effect, reducing the risk of Type II errors (false negatives).\n",
    "\n",
    "**What are you testing?** \n",
    "\n",
    "This study uses **One-Sample Proportion Test** with the following null and alternative hypotheses:\n",
    "\n",
    "- **Null Hypothesis:** The LLM's performance performs worse than the baseline PCC by a meaningful margin.  \n",
    "  $$\n",
    "  H_0: p \\leq p_{\\text{PCC}}\n",
    "  $$\n",
    "  where $p_{\\text{PCC}}$ is the expected accuracy of a random classifier given the outcome distribution.  \n",
    "\n",
    "- **Alternative Hypothesis** The LLM's performance exceeds the PCC by a meaningful margin.  \n",
    "  $$\n",
    "  H_A: p >> p_{\\text{PCC}}\n",
    "  $$\n",
    "  \n",
    "**What do you need?**   \n",
    "\n",
    "1. **Significance Level** ($\\alpha$) – The probability of making a Type I error (commonly set at 0.05). However, since we simultaneously testing multiple hypotheses, we instead set FWER $\\alpha$ to 0.05. The significance level for each test $\\alpha'$ is then set to $\\alpha' = \\frac{0.05}{m}$.\n",
    "2. **Statistical Power** ($1-\\beta$) – The probability of correctly rejecting the null hypothesis (commonly set at 80% or 90%).\n",
    "3. **Effect Size** – The effect size is calculated as the Cohen's $h$ between $p$ and $p_{PCC}$. However, to establish meaningful improvement, we are only interested in $p$ that would generate the desired improvement of $ p_{\\text{Target}} = 1.25 \\times p_{\\text{PCC}}$ for balanced outcomes, and of at least $p_{\\text{Target}} = 1.15 \\times p_{\\text{PCC}}$ for imbalanced outcomes.\n",
    "4. **Test Type** – One-tailed or two-tailed test.\n",
    "\n",
    "**How to code it?**\n",
    "\n",
    "`pwr.p.test(sig.level = alpha, power = power, h = h, alternative = \"greater\")`\n",
    "\n",
    "1. `sig.level` is the **Significance Level**\n",
    "2. `power` is the **Statistical Power**\n",
    "3. `h` is the **Effect Size**, calculated as `ES.h(p_target, pcc)` \n",
    "4. `alternative` is the **Test Type**, `greater` since we are interested in gathering evidence to support $H_A: p >> p_{\\text{PCC}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create reference dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 14 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>name</th><th scope=col>cat_1</th><th scope=col>cat_2</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Interviewer Challenges?          </td><td>3491</td><td>4983</td></tr>\n",
       "\t<tr><td>Level of Challenge by Interviewer</td><td> 942</td><td>2549</td></tr>\n",
       "\t<tr><td>Israeli Perspective              </td><td>2340</td><td>6134</td></tr>\n",
       "\t<tr><td>Palestinian Perspective          </td><td> 217</td><td>8257</td></tr>\n",
       "\t<tr><td>Indiv Humanization Level         </td><td>1085</td><td>7389</td></tr>\n",
       "\t<tr><td>Is Hard Ride                     </td><td>1467</td><td>7007</td></tr>\n",
       "\t<tr><td>Final Rating                     </td><td> 458</td><td>1009</td></tr>\n",
       "\t<tr><td>Casualties - Body                </td><td>2765</td><td>5687</td></tr>\n",
       "\t<tr><td>Victim Sympathy                  </td><td> 721</td><td>1411</td></tr>\n",
       "\t<tr><td>Justification                    </td><td> 741</td><td>1394</td></tr>\n",
       "\t<tr><td>Challenge to justification       </td><td> 322</td><td> 419</td></tr>\n",
       "\t<tr><td>Casualties - 5 sentence          </td><td> 752</td><td>7702</td></tr>\n",
       "\t<tr><td>War Crimes Allegation Presence?  </td><td> 436</td><td> 622</td></tr>\n",
       "\t<tr><td>War Crimes Perpetrator Mentioned?</td><td> 375</td><td> 684</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 14 × 3\n",
       "\\begin{tabular}{lll}\n",
       " name & cat\\_1 & cat\\_2\\\\\n",
       " <chr> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t Interviewer Challenges?           & 3491 & 4983\\\\\n",
       "\t Level of Challenge by Interviewer &  942 & 2549\\\\\n",
       "\t Israeli Perspective               & 2340 & 6134\\\\\n",
       "\t Palestinian Perspective           &  217 & 8257\\\\\n",
       "\t Indiv Humanization Level          & 1085 & 7389\\\\\n",
       "\t Is Hard Ride                      & 1467 & 7007\\\\\n",
       "\t Final Rating                      &  458 & 1009\\\\\n",
       "\t Casualties - Body                 & 2765 & 5687\\\\\n",
       "\t Victim Sympathy                   &  721 & 1411\\\\\n",
       "\t Justification                     &  741 & 1394\\\\\n",
       "\t Challenge to justification        &  322 &  419\\\\\n",
       "\t Casualties - 5 sentence           &  752 & 7702\\\\\n",
       "\t War Crimes Allegation Presence?   &  436 &  622\\\\\n",
       "\t War Crimes Perpetrator Mentioned? &  375 &  684\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 14 × 3\n",
       "\n",
       "| name &lt;chr&gt; | cat_1 &lt;dbl&gt; | cat_2 &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| Interviewer Challenges?           | 3491 | 4983 |\n",
       "| Level of Challenge by Interviewer |  942 | 2549 |\n",
       "| Israeli Perspective               | 2340 | 6134 |\n",
       "| Palestinian Perspective           |  217 | 8257 |\n",
       "| Indiv Humanization Level          | 1085 | 7389 |\n",
       "| Is Hard Ride                      | 1467 | 7007 |\n",
       "| Final Rating                      |  458 | 1009 |\n",
       "| Casualties - Body                 | 2765 | 5687 |\n",
       "| Victim Sympathy                   |  721 | 1411 |\n",
       "| Justification                     |  741 | 1394 |\n",
       "| Challenge to justification        |  322 |  419 |\n",
       "| Casualties - 5 sentence           |  752 | 7702 |\n",
       "| War Crimes Allegation Presence?   |  436 |  622 |\n",
       "| War Crimes Perpetrator Mentioned? |  375 |  684 |\n",
       "\n"
      ],
      "text/plain": [
       "   name                              cat_1 cat_2\n",
       "1  Interviewer Challenges?           3491  4983 \n",
       "2  Level of Challenge by Interviewer  942  2549 \n",
       "3  Israeli Perspective               2340  6134 \n",
       "4  Palestinian Perspective            217  8257 \n",
       "5  Indiv Humanization Level          1085  7389 \n",
       "6  Is Hard Ride                      1467  7007 \n",
       "7  Final Rating                       458  1009 \n",
       "8  Casualties - Body                 2765  5687 \n",
       "9  Victim Sympathy                    721  1411 \n",
       "10 Justification                      741  1394 \n",
       "11 Challenge to justification         322   419 \n",
       "12 Casualties - 5 sentence            752  7702 \n",
       "13 War Crimes Allegation Presence?    436   622 \n",
       "14 War Crimes Perpetrator Mentioned?  375   684 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the dataframe\n",
    "df <- data.frame(\n",
    "    name = c(\n",
    "        'Interviewer Challenges?',\n",
    "        'Level of Challenge by Interviewer',\n",
    "        'Israeli Perspective',\n",
    "        'Palestinian Perspective',\n",
    "        'Indiv Humanization Level',\n",
    "        'Is Hard Ride',\n",
    "        'Final Rating',\n",
    "        'Casualties - Body',\n",
    "        'Victim Sympathy',\n",
    "        'Justification',\n",
    "        'Challenge to justification',\n",
    "        'Casualties - 5 sentence',\n",
    "        'War Crimes Allegation Presence?',\n",
    "        'War Crimes Perpetrator Mentioned?'\n",
    "    ),\n",
    "    cat_1 = c(3491, 942, 2340, 217, 1085, 1467, 458, 2765, 721, 741, 322, 752, 436, 375),\n",
    "    cat_2 = c(4983, 2549, 6134, 8257, 7389, 7007, 1009, 5687, 1411, 1394, 419, 7702, 622, 684)\n",
    ")\n",
    "                  \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control FWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "no_of_tests <- 20\n",
    "fwer_alpha <- alpha/no_of_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Size Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>name</th><th scope=col>cat_1</th><th scope=col>cat_2</th><th scope=col>distribution</th><th scope=col>multiplier</th><th scope=col>pcc</th><th scope=col>min_target_acc</th><th scope=col>desired_accs</th><th scope=col>n</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>War Crimes Allegation Presence?</td><td>436</td><td>622</td><td>0.5879017</td><td>1.25</td><td>0.5154534</td><td>0.6443168</td><td>0.6443168</td><td>1942</td></tr>\n",
       "\t<tr><td>War Crimes Allegation Presence?</td><td>436</td><td>622</td><td>0.5879017</td><td>1.25</td><td>0.5154534</td><td>0.6443168</td><td>0.8000000</td><td> 355</td></tr>\n",
       "\t<tr><td>War Crimes Allegation Presence?</td><td>436</td><td>622</td><td>0.5879017</td><td>1.25</td><td>0.5154534</td><td>0.6443168</td><td>0.8500000</td><td> 241</td></tr>\n",
       "\t<tr><td>War Crimes Allegation Presence?</td><td>436</td><td>622</td><td>0.5879017</td><td>1.25</td><td>0.5154534</td><td>0.6443168</td><td>0.9000000</td><td> 166</td></tr>\n",
       "\t<tr><td>War Crimes Allegation Presence?</td><td>436</td><td>622</td><td>0.5879017</td><td>1.25</td><td>0.5154534</td><td>0.6443168</td><td>0.9500000</td><td> 113</td></tr>\n",
       "\t<tr><td>War Crimes Allegation Presence?</td><td>436</td><td>622</td><td>0.5879017</td><td>1.25</td><td>0.5154534</td><td>0.6443168</td><td>0.9700000</td><td>  94</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 9\n",
       "\\begin{tabular}{lllllllll}\n",
       " name & cat\\_1 & cat\\_2 & distribution & multiplier & pcc & min\\_target\\_acc & desired\\_accs & n\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t War Crimes Allegation Presence? & 436 & 622 & 0.5879017 & 1.25 & 0.5154534 & 0.6443168 & 0.6443168 & 1942\\\\\n",
       "\t War Crimes Allegation Presence? & 436 & 622 & 0.5879017 & 1.25 & 0.5154534 & 0.6443168 & 0.8000000 &  355\\\\\n",
       "\t War Crimes Allegation Presence? & 436 & 622 & 0.5879017 & 1.25 & 0.5154534 & 0.6443168 & 0.8500000 &  241\\\\\n",
       "\t War Crimes Allegation Presence? & 436 & 622 & 0.5879017 & 1.25 & 0.5154534 & 0.6443168 & 0.9000000 &  166\\\\\n",
       "\t War Crimes Allegation Presence? & 436 & 622 & 0.5879017 & 1.25 & 0.5154534 & 0.6443168 & 0.9500000 &  113\\\\\n",
       "\t War Crimes Allegation Presence? & 436 & 622 & 0.5879017 & 1.25 & 0.5154534 & 0.6443168 & 0.9700000 &   94\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 9\n",
       "\n",
       "| name &lt;chr&gt; | cat_1 &lt;dbl&gt; | cat_2 &lt;dbl&gt; | distribution &lt;dbl&gt; | multiplier &lt;dbl&gt; | pcc &lt;dbl&gt; | min_target_acc &lt;dbl&gt; | desired_accs &lt;dbl&gt; | n &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| War Crimes Allegation Presence? | 436 | 622 | 0.5879017 | 1.25 | 0.5154534 | 0.6443168 | 0.6443168 | 1942 |\n",
       "| War Crimes Allegation Presence? | 436 | 622 | 0.5879017 | 1.25 | 0.5154534 | 0.6443168 | 0.8000000 |  355 |\n",
       "| War Crimes Allegation Presence? | 436 | 622 | 0.5879017 | 1.25 | 0.5154534 | 0.6443168 | 0.8500000 |  241 |\n",
       "| War Crimes Allegation Presence? | 436 | 622 | 0.5879017 | 1.25 | 0.5154534 | 0.6443168 | 0.9000000 |  166 |\n",
       "| War Crimes Allegation Presence? | 436 | 622 | 0.5879017 | 1.25 | 0.5154534 | 0.6443168 | 0.9500000 |  113 |\n",
       "| War Crimes Allegation Presence? | 436 | 622 | 0.5879017 | 1.25 | 0.5154534 | 0.6443168 | 0.9700000 |   94 |\n",
       "\n"
      ],
      "text/plain": [
       "  name                            cat_1 cat_2 distribution multiplier pcc      \n",
       "1 War Crimes Allegation Presence? 436   622   0.5879017    1.25       0.5154534\n",
       "2 War Crimes Allegation Presence? 436   622   0.5879017    1.25       0.5154534\n",
       "3 War Crimes Allegation Presence? 436   622   0.5879017    1.25       0.5154534\n",
       "4 War Crimes Allegation Presence? 436   622   0.5879017    1.25       0.5154534\n",
       "5 War Crimes Allegation Presence? 436   622   0.5879017    1.25       0.5154534\n",
       "6 War Crimes Allegation Presence? 436   622   0.5879017    1.25       0.5154534\n",
       "  min_target_acc desired_accs n   \n",
       "1 0.6443168      0.6443168    1942\n",
       "2 0.6443168      0.8000000     355\n",
       "3 0.6443168      0.8500000     241\n",
       "4 0.6443168      0.9000000     166\n",
       "5 0.6443168      0.9500000     113\n",
       "6 0.6443168      0.9700000      94"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var = 'War Crimes Allegation Presence?'\n",
    "cat_1 <- df %>% filter(name == var) %>% pull(cat_1)\n",
    "cat_2 <- df %>% filter(name == var) %>% pull(cat_2)\n",
    "cat_counts <- c(cat_1, cat_2)\n",
    "range_accs <- c(0.80, 0.85, 0.90, 0.95, 0.97)\n",
    "\n",
    "calculate_n_across_accs(name=var, cat_counts=cat_counts, accs=range_accs, alpha=fwer_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>name</th><th scope=col>cat_1</th><th scope=col>cat_2</th><th scope=col>distribution</th><th scope=col>multiplier</th><th scope=col>pcc</th><th scope=col>min_target_acc</th><th scope=col>desired_accs</th><th scope=col>n</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>War Crimes Perpetrator Mentioned?</td><td>375</td><td>684</td><td>0.6458924</td><td>1.25</td><td>0.5425692</td><td>0.6782114</td><td>0.6782114</td><td>1708</td></tr>\n",
       "\t<tr><td>War Crimes Perpetrator Mentioned?</td><td>375</td><td>684</td><td>0.6458924</td><td>1.25</td><td>0.5425692</td><td>0.6782114</td><td>0.8000000</td><td> 428</td></tr>\n",
       "\t<tr><td>War Crimes Perpetrator Mentioned?</td><td>375</td><td>684</td><td>0.6458924</td><td>1.25</td><td>0.5425692</td><td>0.6782114</td><td>0.8500000</td><td> 280</td></tr>\n",
       "\t<tr><td>War Crimes Perpetrator Mentioned?</td><td>375</td><td>684</td><td>0.6458924</td><td>1.25</td><td>0.5425692</td><td>0.6782114</td><td>0.9000000</td><td> 188</td></tr>\n",
       "\t<tr><td>War Crimes Perpetrator Mentioned?</td><td>375</td><td>684</td><td>0.6458924</td><td>1.25</td><td>0.5425692</td><td>0.6782114</td><td>0.9500000</td><td> 125</td></tr>\n",
       "\t<tr><td>War Crimes Perpetrator Mentioned?</td><td>375</td><td>684</td><td>0.6458924</td><td>1.25</td><td>0.5425692</td><td>0.6782114</td><td>0.9700000</td><td> 103</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 9\n",
       "\\begin{tabular}{lllllllll}\n",
       " name & cat\\_1 & cat\\_2 & distribution & multiplier & pcc & min\\_target\\_acc & desired\\_accs & n\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t War Crimes Perpetrator Mentioned? & 375 & 684 & 0.6458924 & 1.25 & 0.5425692 & 0.6782114 & 0.6782114 & 1708\\\\\n",
       "\t War Crimes Perpetrator Mentioned? & 375 & 684 & 0.6458924 & 1.25 & 0.5425692 & 0.6782114 & 0.8000000 &  428\\\\\n",
       "\t War Crimes Perpetrator Mentioned? & 375 & 684 & 0.6458924 & 1.25 & 0.5425692 & 0.6782114 & 0.8500000 &  280\\\\\n",
       "\t War Crimes Perpetrator Mentioned? & 375 & 684 & 0.6458924 & 1.25 & 0.5425692 & 0.6782114 & 0.9000000 &  188\\\\\n",
       "\t War Crimes Perpetrator Mentioned? & 375 & 684 & 0.6458924 & 1.25 & 0.5425692 & 0.6782114 & 0.9500000 &  125\\\\\n",
       "\t War Crimes Perpetrator Mentioned? & 375 & 684 & 0.6458924 & 1.25 & 0.5425692 & 0.6782114 & 0.9700000 &  103\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 9\n",
       "\n",
       "| name &lt;chr&gt; | cat_1 &lt;dbl&gt; | cat_2 &lt;dbl&gt; | distribution &lt;dbl&gt; | multiplier &lt;dbl&gt; | pcc &lt;dbl&gt; | min_target_acc &lt;dbl&gt; | desired_accs &lt;dbl&gt; | n &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| War Crimes Perpetrator Mentioned? | 375 | 684 | 0.6458924 | 1.25 | 0.5425692 | 0.6782114 | 0.6782114 | 1708 |\n",
       "| War Crimes Perpetrator Mentioned? | 375 | 684 | 0.6458924 | 1.25 | 0.5425692 | 0.6782114 | 0.8000000 |  428 |\n",
       "| War Crimes Perpetrator Mentioned? | 375 | 684 | 0.6458924 | 1.25 | 0.5425692 | 0.6782114 | 0.8500000 |  280 |\n",
       "| War Crimes Perpetrator Mentioned? | 375 | 684 | 0.6458924 | 1.25 | 0.5425692 | 0.6782114 | 0.9000000 |  188 |\n",
       "| War Crimes Perpetrator Mentioned? | 375 | 684 | 0.6458924 | 1.25 | 0.5425692 | 0.6782114 | 0.9500000 |  125 |\n",
       "| War Crimes Perpetrator Mentioned? | 375 | 684 | 0.6458924 | 1.25 | 0.5425692 | 0.6782114 | 0.9700000 |  103 |\n",
       "\n"
      ],
      "text/plain": [
       "  name                              cat_1 cat_2 distribution multiplier\n",
       "1 War Crimes Perpetrator Mentioned? 375   684   0.6458924    1.25      \n",
       "2 War Crimes Perpetrator Mentioned? 375   684   0.6458924    1.25      \n",
       "3 War Crimes Perpetrator Mentioned? 375   684   0.6458924    1.25      \n",
       "4 War Crimes Perpetrator Mentioned? 375   684   0.6458924    1.25      \n",
       "5 War Crimes Perpetrator Mentioned? 375   684   0.6458924    1.25      \n",
       "6 War Crimes Perpetrator Mentioned? 375   684   0.6458924    1.25      \n",
       "  pcc       min_target_acc desired_accs n   \n",
       "1 0.5425692 0.6782114      0.6782114    1708\n",
       "2 0.5425692 0.6782114      0.8000000     428\n",
       "3 0.5425692 0.6782114      0.8500000     280\n",
       "4 0.5425692 0.6782114      0.9000000     188\n",
       "5 0.5425692 0.6782114      0.9500000     125\n",
       "6 0.5425692 0.6782114      0.9700000     103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var = 'War Crimes Perpetrator Mentioned?'\n",
    "cat_1 <- df %>% filter(name == var) %>% pull(cat_1)\n",
    "cat_2 <- df %>% filter(name == var) %>% pull(cat_2)\n",
    "cat_counts <- c(cat_1, cat_2)\n",
    "range_accs <- c(0.80, 0.85, 0.90, 0.95, 0.97)\n",
    "\n",
    "calculate_n_across_accs(name=var, cat_counts=cat_counts, accs=range_accs, alpha=fwer_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outcome is too imbalanced; minimum target accuracy is too high: 109.26%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var <- 'Palestinian Perspective'\n",
    "cat_1 <- df %>% filter(name == var) %>% pull(cat_1)\n",
    "cat_2 <- df %>% filter(name == var) %>% pull(cat_2)\n",
    "cat_counts <- c(cat_1, cat_2)\n",
    "range_accs <- c(0.80, 0.85, 0.90, 0.95, 0.97)\n",
    "\n",
    "calculate_n_across_accs(name=var, cat_counts=cat_counts, accs=range_accs, alpha=fwer_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for Post-Hoc Power Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(xlsx)\n",
    "library(dataiku)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name <- \"1. Victim Sympathy\"\n",
    "content <- dkuManagedFolderDownloadPath(\"m74dUoOQ\",\"human_validation.xlsx\", as=\"raw\")\n",
    "temp_f=tempfile()\n",
    "writeBin(object=content, con=temp_f)\n",
    "df_res <- read.xlsx(temp_f, sheetName=sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Model performs 172.35% better than baseline PCC at controlled FWER alpha = 0.05 and at least the standard 80% power.\"\n"
     ]
    }
   ],
   "source": [
    "# Get PCC from apriori power analysis\n",
    "var = 'Victim Sympathy'\n",
    "cat_1 <- df %>% filter(name == var) %>% pull(cat_1)\n",
    "cat_2 <- df %>% filter(name == var) %>% pull(cat_2)\n",
    "cat_counts <- c(cat_1, cat_2)\n",
    "pcc <- calculate_pcc(cat_counts)\n",
    "\n",
    "# Get p from observed model accuracy\n",
    "observed_acc <- mean(df_res$match)\n",
    "\n",
    "# Check power\n",
    "check_posthoc_power(pcc, observed_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# DRAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get PCC from apriori power analysis\n",
    "var = 'Victim Sympathy'\n",
    "cat_1 <- df %>% filter(name == var) %>% pull(cat_1)\n",
    "cat_2 <- df %>% filter(name == var) %>% pull(cat_2)\n",
    "cat_counts <- c(cat_1, cat_2)\n",
    "pcc <- calculate_pcc(cat_counts)\n",
    "\n",
    "# Get p from observed model accuracy\n",
    "sheet_name <- \"1. Victim Sympathy\"\n",
    "content <- dkuManagedFolderDownloadPath(\"m74dUoOQ\",\"human_validation.xlsx\", as=\"raw\")\n",
    "temp_f=tempfile()\n",
    "writeBin(object=content, con=temp_f)\n",
    "df_res <- read.xlsx(temp_f, sheetName=sheet_name)\n",
    "observed_acc <- mean(df_res$match)\n",
    "\n",
    "# Check power if at least 80%\n",
    "h <- calculate_cohens_h(observed_acc, pcc)\n",
    "multiplier  <- round(observed_acc/pcc*100, 2)\n",
    "power <- pwr.p.test(h = h, sig.level = fwer_alpha, alternative = \"greater\", n = nrow(df_res))$power\n",
    "print(paste0('Model performs ', multiplier, '% better than PCC with ', power*100, '% power.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_res %>% drop_na()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get PCC from apriori power analysis\n",
    "var = 'Interviewer Challenges?'\n",
    "cat_1 <- df %>% filter(name == var) %>% pull(cat_1)\n",
    "cat_2 <- df %>% filter(name == var) %>% pull(cat_2)\n",
    "cat_counts <- c(cat_1, cat_2)\n",
    "pcc <- calculate_pcc(cat_counts)\n",
    "\n",
    "# Get p from observed model accuracy\n",
    "sheet_name <- \"2. Interviewer Challenges\"\n",
    "content <- dkuManagedFolderDownloadPath(\"m74dUoOQ\",\"human_validation.xlsx\", as=\"raw\")\n",
    "temp_f=tempfile()\n",
    "writeBin(object=content, con=temp_f)\n",
    "df_res <- read.xlsx(temp_f, sheetName=sheet_name)\n",
    "colnames(df_res) <- c('analysis_id', 'ai_rating', 'human_rating', 'match')\n",
    "observed_acc <- df_res %>% drop_na() %>% pull(match) %>% mean()\n",
    "\n",
    "# Check power if at least 80%\n",
    "h <- calculate_cohens_h(observed_acc, pcc)\n",
    "multiplier  <- round(observed_acc/pcc*100, 2)\n",
    "power <- pwr.p.test(h = h, sig.level = fwer_alpha, alternative = \"greater\", n = nrow(df_res))$power\n",
    "print(paste0('Model performs ', multiplier, '% better than PCC with ', power*100, '% power.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get PCC from apriori power analysis\n",
    "var = 'Israeli Perspective'\n",
    "cat_1 <- df %>% filter(name == var) %>% pull(cat_1)\n",
    "cat_2 <- df %>% filter(name == var) %>% pull(cat_2)\n",
    "cat_counts <- c(cat_1, cat_2)\n",
    "pcc <- calculate_pcc(cat_counts)\n",
    "\n",
    "# Get p from observed model accuracy\n",
    "sheet_name <- \"3. Israeli Perspective\"\n",
    "content <- dkuManagedFolderDownloadPath(\"m74dUoOQ\",\"human_validation.xlsx\", as=\"raw\")\n",
    "temp_f=tempfile()\n",
    "writeBin(object=content, con=temp_f)\n",
    "df_res <- read.xlsx(temp_f, sheetName=sheet_name)\n",
    "colnames(df_res) <- c('analysis_id', 'ai_rating', 'human_rating', 'match')\n",
    "observed_acc <- df_res %>% drop_na() %>% pull(match) %>% mean()\n",
    "\n",
    "# Check power if at least 80%\n",
    "h <- calculate_cohens_h(observed_acc, pcc)\n",
    "multiplier  <- round(observed_acc/pcc*100, 2)\n",
    "power <- pwr.p.test(h = h, sig.level = fwer_alpha, alternative = \"greater\", n = nrow(df_res))$power\n",
    "print(paste0('Model performs ', multiplier, '% better than PCC with ', power*100, '% power.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get PCC from apriori power analysis\n",
    "var = 'Palestinian Perspective'\n",
    "cat_1 <- df %>% filter(name == var) %>% pull(cat_1)\n",
    "cat_2 <- df %>% filter(name == var) %>% pull(cat_2)\n",
    "cat_counts <- c(cat_1, cat_2)\n",
    "pcc <- calculate_pcc(cat_counts)\n",
    "\n",
    "# Get p from observed model accuracy\n",
    "sheet_name <- \"4. Palestinian Perspective\"\n",
    "content <- dkuManagedFolderDownloadPath(\"m74dUoOQ\",\"human_validation.xlsx\", as=\"raw\")\n",
    "temp_f=tempfile()\n",
    "writeBin(object=content, con=temp_f)\n",
    "df_res <- read.xlsx(temp_f, sheetName=sheet_name)\n",
    "colnames(df_res) <- c('analysis_id', 'ai_rating', 'human_rating', 'match')\n",
    "observed_acc <- df_res %>% drop_na() %>% pull(match) %>% mean()\n",
    "\n",
    "# Check power if at least 80%\n",
    "h <- calculate_cohens_h(observed_acc, pcc)\n",
    "multiplier  <- round(observed_acc/pcc*100, 2)\n",
    "power <- pwr.p.test(h = h, sig.level = fwer_alpha, alternative = \"greater\", n = nrow(df_res))$power\n",
    "print(paste0('Model performs ', multiplier, '% better than PCC with ', power*100, '% power.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get PCC from apriori power analysis\n",
    "var = 'Indiv Humanization Level'\n",
    "cat_1 <- df %>% filter(name == var) %>% pull(cat_1)\n",
    "cat_2 <- df %>% filter(name == var) %>% pull(cat_2)\n",
    "cat_counts <- c(cat_1, cat_2)\n",
    "pcc <- calculate_pcc(cat_counts)\n",
    "\n",
    "# Get p from observed model accuracy\n",
    "sheet_name <- \"5. Indiv Humanization Level\"\n",
    "content <- dkuManagedFolderDownloadPath(\"m74dUoOQ\",\"human_validation.xlsx\", as=\"raw\")\n",
    "temp_f=tempfile()\n",
    "writeBin(object=content, con=temp_f)\n",
    "df_res <- read.xlsx(temp_f, sheetName=sheet_name)\n",
    "colnames(df_res) <- c('analysis_id', 'ai_rating', 'human_rating', 'match')\n",
    "observed_acc <- df_res %>% drop_na() %>% pull(match) %>% mean()\n",
    "\n",
    "# Check power if at least 80%\n",
    "h <- calculate_cohens_h(observed_acc, pcc)\n",
    "multiplier  <- round(observed_acc/pcc*100, 2)\n",
    "power <- pwr.p.test(h = h, sig.level = fwer_alpha, alternative = \"greater\", n = nrow(df_res))$power\n",
    "print(paste0('Model performs ', multiplier, '% better than PCC with ', power*100, '% power.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get PCC from apriori power analysis\n",
    "var = 'Is Hard Ride'\n",
    "cat_1 <- df %>% filter(name == var) %>% pull(cat_1)\n",
    "cat_2 <- df %>% filter(name == var) %>% pull(cat_2)\n",
    "cat_counts <- c(cat_1, cat_2)\n",
    "pcc <- calculate_pcc(cat_counts)\n",
    "\n",
    "# Get p from observed model accuracy\n",
    "sheet_name <- \"6. is Hard Ride\"\n",
    "content <- dkuManagedFolderDownloadPath(\"m74dUoOQ\",\"human_validation.xlsx\", as=\"raw\")\n",
    "temp_f=tempfile()\n",
    "writeBin(object=content, con=temp_f)\n",
    "df_res <- read.xlsx(temp_f, sheetName=sheet_name)\n",
    "colnames(df_res) <- c('analysis_id', 'ai_rating', 'human_rating', 'match')\n",
    "observed_acc <- df_res %>% drop_na() %>% pull(match) %>% mean()\n",
    "\n",
    "# Check power if at least 80%\n",
    "h <- calculate_cohens_h(observed_acc, pcc)\n",
    "multiplier  <- round(observed_acc/pcc*100, 2)\n",
    "power <- pwr.p.test(h = h, sig.level = fwer_alpha, alternative = \"greater\", n = nrow(df_res))$power\n",
    "print(paste0('Model performs ', multiplier, '% better than PCC with ', power*100, '% power.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get PCC from apriori power analysis\n",
    "var = 'Casualties - Body'\n",
    "cat_1 <- df %>% filter(name == var) %>% pull(cat_1)\n",
    "cat_2 <- df %>% filter(name == var) %>% pull(cat_2)\n",
    "cat_counts <- c(cat_1, cat_2)\n",
    "pcc <- calculate_pcc(cat_counts)\n",
    "\n",
    "# Get p from observed model accuracy\n",
    "sheet_name <- \"7. Casualties - Body\"\n",
    "content <- dkuManagedFolderDownloadPath(\"m74dUoOQ\",\"human_validation.xlsx\", as=\"raw\")\n",
    "temp_f=tempfile()\n",
    "writeBin(object=content, con=temp_f)\n",
    "df_res <- read.xlsx(temp_f, sheetName=sheet_name)\n",
    "colnames(df_res) <- c('analysis_id', 'ai_rating', 'human_rating', 'match')\n",
    "observed_acc <- df_res %>% drop_na() %>% pull(match) %>% mean()\n",
    "\n",
    "# Check power if at least 80%\n",
    "h <- calculate_cohens_h(observed_acc, pcc)\n",
    "multiplier  <- round(observed_acc/pcc*100, 2)\n",
    "power <- pwr.p.test(h = h, sig.level = fwer_alpha, alternative = \"greater\", n = nrow(df_res))$power\n",
    "print(paste0('Model performs ', multiplier, '% better than PCC with ', power*100, '% power.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get PCC from apriori power analysis\n",
    "var = 'Casualties - 5 sentence'\n",
    "cat_1 <- df %>% filter(name == var) %>% pull(cat_1)\n",
    "cat_2 <- df %>% filter(name == var) %>% pull(cat_2)\n",
    "cat_counts <- c(cat_1, cat_2)\n",
    "pcc <- calculate_pcc(cat_counts)\n",
    "\n",
    "# Get p from observed model accuracy\n",
    "sheet_name <- \"8. Casualties - 5 Sentence\"\n",
    "content <- dkuManagedFolderDownloadPath(\"m74dUoOQ\",\"human_validation.xlsx\", as=\"raw\")\n",
    "temp_f=tempfile()\n",
    "writeBin(object=content, con=temp_f)\n",
    "df_res <- read.xlsx(temp_f, sheetName=sheet_name)\n",
    "colnames(df_res) <- c('analysis_id', 'ai_rating', 'human_rating', 'match')\n",
    "observed_acc <- df_res %>% drop_na() %>% pull(match) %>% mean()\n",
    "\n",
    "# Check power if at least 80%\n",
    "h <- calculate_cohens_h(observed_acc, pcc)\n",
    "multiplier  <- round(observed_acc/pcc*100, 2)\n",
    "power <- pwr.p.test(h = h, sig.level = fwer_alpha, alternative = \"greater\", n = nrow(df_res))$power\n",
    "print(paste0('Model performs ', multiplier, '% better than PCC with ', power*100, '% power.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get PCC from apriori power analysis\n",
    "var = 'War Crimes Allegation Presence?'\n",
    "cat_1 <- df %>% filter(name == var) %>% pull(cat_1)\n",
    "cat_2 <- df %>% filter(name == var) %>% pull(cat_2)\n",
    "cat_counts <- c(cat_1, cat_2)\n",
    "pcc <- calculate_pcc(cat_counts)\n",
    "\n",
    "# Get p from observed model accuracy\n",
    "sheet_name <- \"9. War Crimes Allegation Presen\"\n",
    "content <- dkuManagedFolderDownloadPath(\"m74dUoOQ\",\"human_validation.xlsx\", as=\"raw\")\n",
    "temp_f=tempfile()\n",
    "writeBin(object=content, con=temp_f)\n",
    "df_res <- read.xlsx(temp_f, sheetName=sheet_name)\n",
    "colnames(df_res) <- c('analysis_id', 'ai_rating', 'human_rating', 'match')\n",
    "observed_acc <- df_res %>% drop_na() %>% pull(match) %>% mean()\n",
    "\n",
    "# Check power if at least 80%\n",
    "h <- calculate_cohens_h(observed_acc, pcc)\n",
    "multiplier  <- round(observed_acc/pcc*100, 2)\n",
    "power <- pwr.p.test(h = h, sig.level = fwer_alpha, alternative = \"greater\", n = nrow(df_res))$power\n",
    "print(paste0('Model performs ', multiplier, '% better than PCC with ', power*100, '% power.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get PCC from apriori power analysis\n",
    "var = 'War Crimes Perpetrator Mentioned?'\n",
    "cat_1 <- df %>% filter(name == var) %>% pull(cat_1)\n",
    "cat_2 <- df %>% filter(name == var) %>% pull(cat_2)\n",
    "cat_counts <- c(cat_1, cat_2)\n",
    "pcc <- calculate_pcc(cat_counts)\n",
    "\n",
    "# Get p from observed model accuracy\n",
    "sheet_name <- \"10. War Crimes Perpetrator Ment\"\n",
    "content <- dkuManagedFolderDownloadPath(\"m74dUoOQ\",\"human_validation.xlsx\", as=\"raw\")\n",
    "temp_f=tempfile()\n",
    "writeBin(object=content, con=temp_f)\n",
    "df_res <- read.xlsx(temp_f, sheetName=sheet_name)\n",
    "colnames(df_res) <- c('analysis_id', 'ai_rating', 'human_rating', 'match')\n",
    "observed_acc <- df_res %>% drop_na() %>% pull(match) %>% mean()\n",
    "\n",
    "# Check power if at least 80%\n",
    "h <- calculate_cohens_h(observed_acc, pcc)\n",
    "multiplier  <- round(observed_acc/pcc*100, 2)\n",
    "power <- pwr.p.test(h = h, sig.level = fwer_alpha, alternative = \"greater\", n = nrow(df_res))$power\n",
    "print(paste0('Model performs ', multiplier, '% better than PCC with ', power*100, '% power.'))"
   ]
  }
 ],
 "metadata": {
  "createdOn": 1742181493550,
  "creator": "donatpat",
  "customFields": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "R (env team_phs-mktteam_conda_r)",
   "language": "R",
   "name": "r-dku-venv-team_phs-mktteam_conda_r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  },
  "modifiedBy": "donatpat",
  "tags": []
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
